defaults:

  # Train Script
  logdir: /dev/null
  load_logdir: none
  seed: 0
  device: cuda
  wandb: {project: 'world-model',name: 'apv_finetuning',mode: 'online'}
  task: metaworld_drawer_open
  envs: 1
  envs_parallel: none
  render_size: [64, 64]
  dmc_camera: -1
  camera: corner
  dmcr_vary: all
  atari_grayscale: True
  time_limit: 0
  action_repeat: 1
  steps: 1e8
  log_every: 1e4
  eval_every: 1e4
  eval_eps: 1
  prefill: 10000
  pretrain: 100
  train_every: 5
  train_steps: 1
  expl_until: 0
  replay: {capacity: 1e6, ongoing: False, minlen: 50, maxlen: 50, prioritize_ends: True}
  dataset: {batch: 16, length: 50}
  log_keys_video: ['image']
  log_keys_sum: '^$'
  log_keys_mean: '^$'
  log_keys_max: '^$'
  precision: 16
  jit: True
  stop_steps: -1

  # CARLA
  carla_port: 2000
  carla: {
    collision_coeff: 1e-3,
    num_other_vehicles: 20,
    centering_reward_type: div,
    centering_reward_weight: 1.0,
    clip_collision_reward: 10.0,
    steer_coeff: 1.0,
    centering_border: 1.75,
    use_branch_lane_cut: True,
    changing_weather_speed: 0.1,
  }

  # Agent
  clip_rewards: identity
  expl_behavior: greedy
  expl_noise: 0.0
  eval_noise: 0.0
  eval_state_mean: False

  # Fine-tuning parameters
  load_modules: [encoder, decoder, af_rssm]
  load_strict: True
  enc_lr_type: no_pretrain
  concat_embed: False

  # Intrinsic bonus parameters
  k: 16
  beta: 1.0
  beta_type: abs
  intr_seq_length: 5
  intr_reward_norm: {momentum: 0.99, scale: 1.0, eps: 1e-8, init: 1.0}
  queue_size: 4096
  queue_dim: 128

  # World Model
  grad_heads: [decoder, reward]
  pred_discount: False
  rssm: {action_free: False, fill_action: 50, ensemble: 1, embed_dim: 2048,hidden: 1024, deter: 1024, stoch: 32, discrete: 32, act: elu, norm: none, std_act: sigmoid2, min_std: 0.1}
  af_rssm: {action_free: True, fill_action: 50, ensemble: 1, embed_dim: 3072,hidden: 1024, deter: 1024, stoch: 32, discrete: 32, act: elu, norm: none, std_act: sigmoid2, min_std: 0.1}
  encoder_type: resnet # ['plaincnn', 'resnet', 'deco_resnet']
  encoder: {
    mlp_keys: '.*', 
    cnn_keys: '.*', 
    act: elu, 
    norm: none, 
    cnn_depth: 48, 
    cnn_kernels: [4, 4, 4, 4], 
    mlp_layers: [400, 400, 400, 400], 
    res_norm: 'batch',
    res_depth: 3,
    res_layers: 2,
  }
  decoder_type: resnet # ['plaincnn', 'resnet', 'deco_resnet']
  decoder: {
    mlp_keys: '.*', 
    cnn_keys: '.*', 
    act: elu, 
    norm: none, 
    cnn_depth: 48, 
    cnn_kernels: [5, 5, 6, 6], 
    mlp_layers: [400, 400, 400, 400], 
    res_norm: 'batch',
    res_depth: 3,
    res_layers: 2,
  }
  reward_head: {layers: 4, input_dim: 2048, units: 400, act: elu, norm: none, dist: mse}
  discount_head: {layers: 4, units: 400, act: elu, norm: none, dist: binary}
  loss_scales: {
    af_kl: 0.0, 
    kl: 1.0, 
    reward: 1.0, 
    action: 1.0, 
    discount: 1.0, 
    proprio: 1.0,
    aux_reward: 0.0,
  }
  kl: {free: 0.0, forward: False, balance: 0.8, free_avg: True}
  model_opt: {opt: adam, lr: 3e-4, eps: 1e-5, clip: 100, wd: 1e-6}
  enc_model_opt: {opt: adam, lr: 3e-4, eps: 1e-5, clip: 100, wd: 1e-6}

  # Actor Critic
  actor: {layers: 4, input_dim: 2048, units: 400, act: elu, norm: none, dist: auto, min_std: 0.1}
  critic: {layers: 4, input_dim: 2048, units: 400, act: elu, norm: none, dist: mse}
  actor_opt: {opt: adam, lr: 8e-5, eps: 1e-5, clip: 100, wd: 1e-6}
  critic_opt: {opt: adam, lr: 8e-5, eps: 1e-5, clip: 100, wd: 1e-6}
  discount: 0.99
  discount_lambda: 0.95
  imag_horizon: 15
  imag_batch: -1
  actor_grad: auto
  actor_grad_mix: 0.1
  actor_ent: 1e-4
  slow_target: True
  slow_target_update: 100
  slow_target_fraction: 1
  slow_baseline: True
  reward_norm: {momentum: 1.0, scale: 1.0, eps: 1e-8}

  # Exploration
  expl_intr_scale: 1.0
  expl_extr_scale: 0.0
  expl_opt: {opt: adam, lr: 3e-4, eps: 1e-5, clip: 100, wd: 1e-6}
  expl_head: {layers: 4, units: 400, act: elu, norm: none, dist: mse}
  expl_reward_norm: {momentum: 1.0, scale: 1.0, eps: 1e-8}
  disag_target: stoch
  disag_log: False
  disag_models: 10
  disag_offset: 1
  disag_action_cond: True
  expl_model_loss: kl

  # Contextualized World Model (subset of Decoupled World Model)
  # Decoupled World Model 
  encoder_deco: { 
    deco_res_layers: 2,
    deco_cnn_depth: 48,
    deco_cond_choice: trand,
    ctx_aug: none, 
  }
  decoder_deco: {
    deco_attmask: 0.75,
    ctx_attmaskwarmup: -1,
  }


metaworld:

  task: metaworld_drawer_open
  encoder: {mlp_keys: '$^', cnn_keys: 'image'}
  decoder: {mlp_keys: '$^', cnn_keys: 'image'}
  dataset: {batch: 50, length: 50}
  time_limit: 500
  action_repeat: 1
  eval_eps: 10
  prefill: 5000
  camera: corner
  steps: 256000
  concat_embed: False
  enc_lr_type: no_pretrain
  beta: 1.0
  stop_steps: 255000

robodesk:

  task: robodesk_open_slide
  encoder: {mlp_keys: '$^', cnn_keys: 'image'}
  decoder: {mlp_keys: '$^', cnn_keys: 'image'}
  dataset: {batch: 50, length: 50}
  time_limit: 500
  action_repeat: 1
  eval_eps: 10
  prefill: 5000
  camera: corner
  steps: 256000
  concat_embed: False
  enc_lr_type: no_pretrain
  beta: 1.0
  stop_steps: 255000


small:
  rssm: {hidden: 200, deter: 200}
  af_rssm: {hidden: 200, deter: 200}


plaincnn:
  encoder_type: plaincnn
  decoder_type: plaincnn


plainresnet:
  encoder_type: resnet
  decoder_type: resnet


contextualized:
  encoder_type: deco_resnet
  decoder_type: deco_resnet
